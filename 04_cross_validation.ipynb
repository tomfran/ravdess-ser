{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmbA4Izxy_Za"
      },
      "outputs": [],
      "source": [
        "COLAB = True\n",
        "\n",
        "if COLAB: \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')\n",
        "  !unzip src.zip\n",
        "  !mkdir data && mkdir data/models\n",
        "  !pip install audiomentations\n",
        "  speech_path, save_path = \"drive/MyDrive/audio-pattern\", \"drive/MyDrive/audio-pattern\"\n",
        "else:\n",
        "  speech_path, save_path = \"data/raw/speech\", \"data/processed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S2_UTsZuy_Zc"
      },
      "outputs": [],
      "source": [
        "from src.data_processing import FeatureExtractor\n",
        "from src.dataset import Dataset\n",
        "from src.loader import Loader, Augmenter\n",
        "from src.models import build_train_simple, train_nn, build_nn, build_cnn, build_lstm\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(1)\n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9ynR2HWay_Zd"
      },
      "outputs": [],
      "source": [
        "loader = Loader(speech_path, save_path, True, 0, -1)\n",
        "orig_data, orig_labels = loader.load(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrNAXC2qy_Ze",
        "outputId": "48cf33ce-499e-45a0-e963-99d80c30b4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename: full found on disk\n",
            "\n",
            "Filename: mfcc found on disk\n",
            "\n",
            "Filename: full_augmented_speed found on disk\n",
            "\n",
            "Filename: mfcc_augmented_speed found on disk\n",
            "\n",
            "Filename: full_augmented_noise found on disk\n",
            "\n",
            "Filename: mfcc_augmented_noise found on disk\n",
            "\n",
            "Filename: full_augmented_pitch found on disk\n",
            "\n",
            "Filename: mfcc_augmented_pitch found on disk\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# original features\n",
        "orig_features, orig_labels = FeatureExtractor(raw_data=orig_data, labels=orig_labels, \n",
        "                                              save_path=f\"{save_path}/features\", \n",
        "                                              file_name=\"full\", verbose=True, \n",
        "                                              only_mfcc=False).get_training_data(overwrite=False)\n",
        "\n",
        "orig_features_mfcc, orig_labels_mfcc = FeatureExtractor(raw_data=orig_data, labels=orig_labels, \n",
        "                                                        save_path=f\"{save_path}/features\", \n",
        "                                                        file_name=\"mfcc\", verbose=True, \n",
        "                                                        only_mfcc=True).get_training_data(overwrite=False)\n",
        "orig_features_mfcc = np.expand_dims(orig_features_mfcc, axis=2)\n",
        "\n",
        "\n",
        "augmented_data_full = []\n",
        "augmented_data_mfcc = []\n",
        "\n",
        "for name in [\"speed\", \"noise\", \"pitch\"]:\n",
        "    full_data, full_labels = FeatureExtractor(raw_data=None, labels=orig_labels, \n",
        "                              save_path=f\"{save_path}/features\", \n",
        "                              file_name=f\"full_augmented_{name}\", verbose=True, \n",
        "                              only_mfcc=False).get_training_data(overwrite=False)\n",
        "    augmented_data_full.append((full_data, full_labels))\n",
        "    \n",
        "    # extract mfcc for cnn\n",
        "    mfcc_data, mfcc_labels = FeatureExtractor(raw_data=None, labels=orig_labels_mfcc, \n",
        "                              save_path=f\"{save_path}/features\", \n",
        "                              file_name=f\"mfcc_augmented_{name}\", verbose=True, \n",
        "                              only_mfcc=True).get_training_data(overwrite=False)\n",
        "    mfcc_data = np.expand_dims(mfcc_data, axis=2)\n",
        "    augmented_data_mfcc.append((mfcc_data, mfcc_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdPWEyGwM6E1",
        "outputId": "7534ac7e-3b8e-400f-e4d4-ef9e795ece28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
            "100%|██████████| 5/5 [00:26<00:00,  5.29s/it]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.tree import DecisionTreeClassifier as Dtree\n",
        "from tqdm import tqdm \n",
        "\n",
        "d = Dataset(original_data=(orig_features, orig_labels), augmented_data=None)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "\n",
        "scores = [[], [], []]\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores[0].append(build_train_simple((X_train, y_train), (X_test, y_test), SVC()))\n",
        "    scores[1].append(build_train_simple((X_train, y_train), (X_test, y_test), KNN(int(len(X_train)**0.5))))\n",
        "    scores[2].append(build_train_simple((X_train, y_train), (X_test, y_test), Dtree(max_depth=10)))\n",
        "    \n",
        "scores = [(np.mean(x), np.std(x)) for x in scores]\n",
        "    \n",
        "d = Dataset(original_data=(orig_features, orig_labels), augmented_data=augmented_data_full)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "\n",
        "scores_aug = [[], [], []]\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores_aug[0].append(build_train_simple((X_train, y_train), (X_test, y_test), SVC()))\n",
        "    scores_aug[1].append(build_train_simple((X_train, y_train), (X_test, y_test), KNN(int(len(X_train)**0.5))))\n",
        "    scores_aug[2].append(build_train_simple((X_train, y_train), (X_test, y_test), Dtree(max_depth=10)))\n",
        "    \n",
        "scores_aug = [(np.mean(x), np.std(x)) for x in scores_aug]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Simple models cross validation scores without augmentation:\\n\")\n",
        "print(\"\\n\".join([f\"\\t- {a:5} : {b:0.3f} (std: {c:0.3f})\" for a, (b, c) in zip([\"Svc\", \"Knn\", \"Dtree\"], scores)]), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Simple models cross validation scores with augmentation:\\n\")\n",
        "print(\"\\n\".join([f\"\\t- {a:5} : {b:0.3f} (std: {c:0.3f})\" for a, (b, c) in zip([\"Svc\", \"Knn\", \"Dtree\"], scores_aug)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0H9uLLpNCq9",
        "outputId": "542efeaa-f3a1-4667-98c8-d94e4aa02fa3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple models cross validation scores without augmentation:\n",
            "\n",
            "\t- Svc   : 0.588 (std: 0.035)\n",
            "\t- Knn   : 0.441 (std: 0.023)\n",
            "\t- Dtree : 0.403 (std: 0.036)\n",
            "\n",
            "Simple models cross validation scores with augmentation:\n",
            "\n",
            "\t- Svc   : 0.643 (std: 0.015)\n",
            "\t- Knn   : 0.422 (std: 0.016)\n",
            "\t- Dtree : 0.421 (std: 0.041)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knsBRb_NM6E3",
        "outputId": "1465b896-f740-4812-8430-f46b044e0d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [16:12<00:00, 194.50s/it]\n",
            "100%|██████████| 5/5 [51:24<00:00, 616.92s/it]\n"
          ]
        }
      ],
      "source": [
        "scores = [[], []]\n",
        "scores_aug = [[], []]\n",
        "\n",
        "d = Dataset(original_data=(orig_features, orig_labels), augmented_data=None)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores[0].append(train_nn((X_train, y_train), (X_test, y_test), build_nn, epochs=1500, verbose=0, plot=False)[1])\n",
        "\n",
        "d = Dataset(original_data=(orig_features, orig_labels), augmented_data=augmented_data_full)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores_aug[0].append(train_nn((X_train, y_train), (X_test, y_test), build_nn, epochs=1500, verbose=0, plot=False)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBS4WKuEM6E4",
        "outputId": "94de85fa-ad39-47dc-9d97-08178913993c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [19:53<00:00, 238.63s/it]\n",
            "100%|██████████| 5/5 [1:06:34<00:00, 798.91s/it]\n"
          ]
        }
      ],
      "source": [
        "scores[1] = []\n",
        "scores_aug[1] = []\n",
        "\n",
        "d = Dataset(original_data=(orig_features_mfcc, orig_labels), augmented_data=None)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores[1].append(train_nn((X_train, y_train), (X_test, y_test), build_cnn, epochs=1500, verbose=0, plot=False)[1])\n",
        "    \n",
        "d = Dataset(original_data=(orig_features_mfcc, orig_labels), augmented_data=augmented_data_mfcc)\n",
        "generator = d.get_cross_val_generator(5)\n",
        "for (X_train, y_train), (X_test, y_test) in tqdm(generator):\n",
        "    scores_aug[1].append(train_nn((X_train, y_train), (X_test, y_test), build_cnn, epochs=1500, verbose=0, plot=False)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiVVde2fM6E5",
        "outputId": "8eee2e33-1cce-45ac-ae2c-180813fc4a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural networks cross validation scores without data augmentation:\n",
            "\n",
            "\t- MLP   : 0.611 (std: 0.031)\n",
            "\t- CNN   : 0.490 (std: 0.058)\n",
            "\n",
            "Neural networks cross validation scores with data augmentation:\n",
            "\n",
            "\t- MLP   : 0.692 (std: 0.012)\n",
            "\t- CNN   : 0.698 (std: 0.030)\n"
          ]
        }
      ],
      "source": [
        "scores = [(np.mean(x), np.std(x)) for x in scores]\n",
        "scores_aug = [(np.mean(x), np.std(x)) for x in scores_aug]\n",
        "\n",
        "print(\"Neural networks cross validation scores without data augmentation:\\n\")\n",
        "print(\"\\n\".join([f\"\\t- {a:5} : {b:0.3f} (std: {c:0.3f})\" for a, (b, c) in zip([\"MLP\", \"CNN\"], scores)]), end = \"\\n\\n\")\n",
        "print(\"Neural networks cross validation scores with data augmentation:\\n\")\n",
        "print(\"\\n\".join([f\"\\t- {a:5} : {b:0.3f} (std: {c:0.3f})\" for a, (b, c) in zip([\"MLP\", \"CNN\"], scores_aug)]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "04_cross_validation.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}